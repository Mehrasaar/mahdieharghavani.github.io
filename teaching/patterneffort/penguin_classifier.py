
import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import time
import json
import os
from datetime import datetime
import hashlib

from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    classification_report, confusion_matrix, roc_curve, auc,
    roc_auc_score, log_loss
)
from sklearn.pipeline import Pipeline

# ============================================
# Û±. ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµÙØ­Ù‡
# ============================================

st.set_page_config(
    page_title="ğŸ§ Ø³ÛŒØ³ØªÙ… Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù¾Ù†Ú¯ÙˆØ¦Ù† | Palmer Station",
    page_icon="ğŸ§",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://github.com/streamlit/streamlit',
        'Report a bug': 'https://github.com/streamlit/streamlit/issues',
        'About': "# Ù¾Ù†Ú¯ÙˆØ¦Ù† Ú©Ù„Ø§Ø³ÛŒÙØ§ÛŒØ±\nØ§ÛŒÙ† Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† Ø¨Ø±Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú¯ÙˆÙ†Ù‡ Ù¾Ù†Ú¯ÙˆØ¦Ù† Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª."
    }
)

# ============================================
# Û². Ø§Ø³ØªØ§ÛŒÙ„ CSS Ø³ÙØ§Ø±Ø´ÛŒ
# ============================================

st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
        padding: 1rem;
        background: linear-gradient(90deg, #E3F2FD, #BBDEFB);
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .prediction-box {
        background-color: #e8f5e9;
        padding: 2rem;
        border-radius: 15px;
        border-left: 5px solid #4CAF50;
        margin: 1rem 0;
    }
    .stButton>button {
        background-color: #1E88E5;
        color: white;
        font-weight: bold;
        border-radius: 10px;
        padding: 0.5rem 2rem;
        border: none;
        transition: all 0.3s;
    }
    .stButton>button:hover {
        background-color: #1565C0;
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
</style>
""", unsafe_allow_html=True)

# ============================================
# Û³. ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ
# ============================================

def generate_session_id():
    """ØªÙˆÙ„ÛŒØ¯ Ø´Ù†Ø§Ø³Ù‡ ÛŒÚ©ØªØ§ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø³Ø´Ù†"""
    return hashlib.md5(str(datetime.now()).encode()).hexdigest()[:8]

@st.cache_data(ttl=3600, show_spinner="ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ù†Ú¯ÙˆØ¦Ù†...")
def load_penguin_data():
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯ÛŒØªØ§Ø³Øª Ù¾Ù†Ú¯ÙˆØ¦Ù†"""
    try:
        df = sns.load_dataset("penguins")
        original_len = len(df)
        df = df.dropna()
        dropped = original_len - len(df)
        
        df["species_code"] = df["species"].astype('category').cat.codes
        df["island_code"] = df["island"].astype('category').cat.codes
        df["sex_code"] = df["sex"].astype('category').cat.codes
        
        df.attrs['loaded_at'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        df.attrs['source'] = "Palmer Station Antarctica"
        df.attrs['dropped_rows'] = dropped
        
        return df
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {str(e)}")
        return None

@st.cache_resource(show_spinner="ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø§ÛŒÙ¾Ù„Ø§ÛŒÙ† Ø¢Ù…ÙˆØ²Ø´...")
def create_pipeline(algorithm, params=None):
    """Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø§ÛŒÙ¾Ù„Ø§ÛŒÙ† ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†"""
    
    # Ù…Ø±Ø­Ù„Ù‡ Û±: Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ
    scaler = StandardScaler()
    
    # Ù…Ø±Ø­Ù„Ù‡ Û²: Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…
    if algorithm == "Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ù„Ø¬Ø³ØªÛŒÚ©":
        classifier = LogisticRegression(random_state=42, max_iter=1000)
        param_grid = {
            'classifier__C': [0.01, 0.1, 1, 10],
            'classifier__solver': ['lbfgs', 'liblinear']
        }
    elif algorithm == "Ø¬Ù†Ú¯Ù„ ØªØµØ§Ø¯ÙÛŒ":
        classifier = RandomForestClassifier(random_state=42)
        param_grid = {
            'classifier__n_estimators': [50, 100, 200],
            'classifier__max_depth': [5, 10, None],
            'classifier__min_samples_split': [2, 5, 10]
        }
    elif algorithm == "SVM":
        classifier = SVC(random_state=42, probability=True)
        param_grid = {
            'classifier__C': [0.1, 1, 10],
            'classifier__kernel': ['rbf', 'poly'],
            'classifier__gamma': ['scale', 'auto']
        }
    elif algorithm == "Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ø¨ÙˆØ³ØªÛŒÙ†Ú¯":
        classifier = GradientBoostingClassifier(random_state=42)
        param_grid = {
            'classifier__n_estimators': [50, 100],
            'classifier__learning_rate': [0.01, 0.1, 0.2],
            'classifier__max_depth': [3, 5]
        }
    else:  # KNN
        classifier = KNeighborsClassifier()
        param_grid = {
            'classifier__n_neighbors': [3, 5, 7, 9],
            'classifier__weights': ['uniform', 'distance']
        }
    
    # Ø³Ø§Ø®Øª Ù¾Ø§ÛŒÙ¾Ù„Ø§ÛŒÙ†
    pipeline = Pipeline([
        ('scaler', scaler),
        ('classifier', classifier)
    ])
    
    return pipeline, param_grid if params is None else None

@st.cache_data(ttl=300)
def train_and_evaluate(X_train, X_test, y_train, y_test, algorithm, use_grid_search=False):
    """Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„"""
    
    pipeline, param_grid = create_pipeline(algorithm)
    
    if use_grid_search and param_grid:
        grid_search = GridSearchCV(
            pipeline, 
            param_grid, 
            cv=5, 
            scoring='accuracy',
            n_jobs=-1,
            verbose=0
        )
        grid_search.fit(X_train, y_train)
        best_model = grid_search.best_estimator_
        best_params = grid_search.best_params_
    else:
        pipeline.fit(X_train, y_train)
        best_model = pipeline
        best_params = None
    
    # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
    y_pred = best_model.predict(X_test)
    y_proba = best_model.predict_proba(X_test) if hasattr(best_model, 'predict_proba') else None
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§
    metrics = {
        'accuracy': accuracy_score(y_test, y_pred),
        'precision_macro': precision_score(y_test, y_pred, average='macro'),
        'recall_macro': recall_score(y_test, y_pred, average='macro'),
        'f1_macro': f1_score(y_test, y_pred, average='macro'),
        'precision_weighted': precision_score(y_test, y_pred, average='weighted'),
        'recall_weighted': recall_score(y_test, y_pred, average='weighted'),
        'f1_weighted': f1_score(y_test, y_pred, average='weighted')
    }
    
    if y_proba is not None:
        try:
            metrics['log_loss'] = log_loss(y_test, y_proba)
            metrics['roc_auc'] = roc_auc_score(y_test, y_proba, multi_class='ovr')
        except:
            pass
    
    return best_model, metrics, y_pred, y_proba, best_params

# ============================================
# Û´. Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Session State
# ============================================

def init_session_state():
    """Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Session State"""
    
    defaults = {
        'session_id': generate_session_id(),
        'model': None,
        'scaler': None,
        'features': [],
        'metrics': {},
        'training_history': [],
        'predictions': [],
        'selected_features': ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g'],
        'algorithm': 'Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ù„Ø¬Ø³ØªÛŒÚ©',
        'test_size': 0.2,
        'use_grid_search': False,
        'dark_mode': False,
        'show_code': False
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

init_session_state()

# ============================================
# Ûµ. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡
# ============================================

df = load_penguin_data()

if df is None:
    st.error("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§. Ù„Ø·ÙØ§ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±Ø§ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯.")
    st.stop()

# ============================================
# Û¶. Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ
# ============================================

st.markdown('<h1 class="main-header">ğŸ§ Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú¯ÙˆÙ†Ù‡ Ù¾Ù†Ú¯ÙˆØ¦Ù† - Ø§ÛŒØ³ØªÚ¯Ø§Ù‡ Ù¾Ø§Ù„Ù…Ø±</h1>', 
            unsafe_allow_html=True)

st.markdown("""
<div style='background-color: #f0f2f6; padding: 20px; border-radius: 10px; margin-bottom: 30px;'>
    <h4>ğŸ¯ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù†</h4>
    <p>
        Ø§ÛŒÙ† Ø³ÛŒØ³ØªÙ… Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†ØŒ Ú¯ÙˆÙ†Ù‡ Ù¾Ù†Ú¯ÙˆØ¦Ù† Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ 
        ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙÛŒØ²ÛŒÚ©ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Ø§ÛŒØ³ØªÚ¯Ø§Ù‡ ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ Palmer Ø¯Ø± Ù‚Ø·Ø¨ Ø¬Ù†ÙˆØ¨ 
        Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯.
    </p>
    <p>
        <b>Ø´Ù†Ø§Ø³Ù‡ Ø³Ø´Ù†:</b> {} | <b>Ø¢Ø®Ø±ÛŒÙ† Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ:</b> {}
    </p>
</div>
""".format(st.session_state.session_id, df.attrs['loaded_at']), unsafe_allow_html=True)

# ============================================
# Û·. Ø³Ø§ÛŒØ¯Ø¨Ø§Ø± - ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ø§Ù…Ù„
# ============================================

with st.sidebar:
    st.image("https://allisonhorst.github.io/palmerpenguins/reference/figures/lter_penguins.png", 
             use_container_width=True)
    
    st.header("âš™ï¸ Ù¾Ù†Ù„ ÙØ±Ù…Ø§Ù†")
    
    with st.expander("ğŸ“Š Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§", expanded=True):
        all_features = ["bill_length_mm", "bill_depth_mm", "flipper_length_mm", "body_mass_g"]
        selected_features = st.multiselect(
            "ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ:",
            all_features,
            default=st.session_state.selected_features,
            help="ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙÛŒØ²ÛŒÚ©ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„"
        )
        st.session_state.selected_features = selected_features
    
    with st.expander("ğŸ¤– ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø¯Ù„", expanded=True):
        algorithm = st.selectbox(
            "Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ:",
            ["Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ù„Ø¬Ø³ØªÛŒÚ©", "Ø¬Ù†Ú¯Ù„ ØªØµØ§Ø¯ÙÛŒ", "SVM", "Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ø¨ÙˆØ³ØªÛŒÙ†Ú¯", "KNN"],
            index=["Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ù„Ø¬Ø³ØªÛŒÚ©", "Ø¬Ù†Ú¯Ù„ ØªØµØ§Ø¯ÙÛŒ", "SVM", "Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ø¨ÙˆØ³ØªÛŒÙ†Ú¯", "KNN"].index(
                st.session_state.algorithm
            ),
            help="Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ"
        )
        st.session_state.algorithm = algorithm
        
        test_size = st.slider(
            "Ø¯Ø±ØµØ¯ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª:",
            min_value=0.1, max_value=0.4, value=st.session_state.test_size, step=0.05,
            format="%d%%",
            help="Ø¯Ø±ØµØ¯ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„"
        )
        st.session_state.test_size = test_size
        
        use_grid_search = st.checkbox(
            "ğŸ” Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± (Grid Search)",
            value=st.session_state.use_grid_search,
            help="Ø¬Ø³ØªØ¬ÙˆÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ù‡ØªØ±ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§"
        )
        st.session_state.use_grid_search = use_grid_search
    
    with st.expander("ğŸ¨ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¸Ø§Ù‡Ø±ÛŒ"):
        dark_mode = st.checkbox("ğŸŒ™ Ø­Ø§Ù„Øª ØªØ§Ø±ÛŒÚ©", value=st.session_state.dark_mode)
        st.session_state.dark_mode = dark_mode
        show_code = st.checkbox("ğŸ“ Ù†Ù…Ø§ÛŒØ´ Ú©Ø¯", value=st.session_state.show_code)
        st.session_state.show_code = show_code
    
    st.divider()
    
    # Ø¯Ú©Ù…Ù‡ Ø¢Ù…ÙˆØ²Ø´
    train_button = st.button(
        "ğŸš€ Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„",
        type="primary",
        use_container_width=True,
        disabled=len(selected_features) < 2
    )
    
    if len(selected_features) < 2:
        st.warning("âš ï¸ Ø­Ø¯Ø§Ù‚Ù„ Û² ÙˆÛŒÚ˜Ú¯ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯")
    
    st.divider()
    
    # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
    st.subheader("ğŸ“Š Ø¢Ù…Ø§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡", f"{len(df):,}")
        st.metric("ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§", df.shape[1] - 4)
    with col2:
        st.metric("Ú¯ÙˆÙ†Ù‡â€ŒÙ‡Ø§", df['species'].nunique())
        st.metric("Ø¬Ø²Ø§ÛŒØ±", df['island'].nunique())
    
    if df.attrs['dropped_rows'] > 0:
        st.caption(f"âš ï¸ {df.attrs['dropped_rows']} Ù†Ù…ÙˆÙ†Ù‡ Ú¯Ù…Ø´Ø¯Ù‡ Ø­Ø°Ù Ø´Ø¯")
    
    st.divider()
    st.caption("ğŸ§ Palmer Penguins v1.0.0")
    st.caption(f"Â© 2026 - Antarctic Research")

# ============================================
# Û¸. Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø§Ú©ØªØ´Ø§ÙÛŒ
# ============================================

tab1, tab2, tab3, tab4 = st.tabs(
    ["ğŸ“‹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ø¢Ù…Ø§Ø±", "ğŸ“ˆ Ù…ØµÙˆØ±Ø³Ø§Ø²ÛŒ", "ğŸ¤– Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ", "ğŸ”® Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ"]
)

with tab1:
    st.header("ğŸ“‹ Ø¨Ø±Ø±Ø³ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("Ù†Ù…ÙˆÙ†Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
        display_cols = ["species", "island", "sex"] + selected_features
        st.dataframe(
            df[display_cols].head(10),
            use_container_width=True,
            hide_index=True,
            column_config={
                "species": "Ú¯ÙˆÙ†Ù‡",
                "island": "Ø¬Ø²ÛŒØ±Ù‡",
                "sex": "Ø¬Ù†Ø³ÛŒØª",
                "bill_length_mm": st.column_config.NumberColumn("Ø·ÙˆÙ„ Ù†ÙˆÚ©", format="%.1f mm"),
                "bill_depth_mm": st.column_config.NumberColumn("Ø¹Ù…Ù‚ Ù†ÙˆÚ©", format="%.1f mm"),
                "flipper_length_mm": st.column_config.NumberColumn("Ø·ÙˆÙ„ Ø¨Ø§Ù„Ú†Ù‡", format="%.0f mm"),
                "body_mass_g": st.column_config.NumberColumn("ÙˆØ²Ù†", format="%.0f g")
            }
        )
    
    with col2:
        st.subheader("Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯ÛŒØªØ§Ø³Øª")
        info_df = pd.DataFrame({
            "Ù…Ø´Ø®ØµÙ‡": ["Ù…Ù†Ø¨Ø¹", "ØªØ§Ø±ÛŒØ® Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ", "ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§", "ØªØ¹Ø¯Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§"],
            "Ù…Ù‚Ø¯Ø§Ø±": [
                df.attrs['source'],
                df.attrs['loaded_at'],
                len(df),
                df.shape[1]
            ]
        })
        st.dataframe(info_df, use_container_width=True, hide_index=True)
    
    st.subheader("ğŸ“Š Ø¢Ù…Ø§Ø± ØªÙˆØµÛŒÙÛŒ")
    
    stat_col1, stat_col2 = st.columns(2)
    
    with stat_col1:
        st.markdown("**ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ**")
        stats_df = df[selected_features].describe().round(2)
        st.dataframe(stats_df, use_container_width=True)
    
    with stat_col2:
        st.markdown("**ØªÙˆØ²ÛŒØ¹ Ú¯ÙˆÙ†Ù‡â€ŒÙ‡Ø§**")
        species_counts = df['species'].value_counts().reset_index()
        species_counts.columns = ['Ú¯ÙˆÙ†Ù‡', 'ØªØ¹Ø¯Ø§Ø¯']
        
        fig = px.pie(
            species_counts,
            values='ØªØ¹Ø¯Ø§Ø¯',
            names='Ú¯ÙˆÙ†Ù‡',
            title="ØªÙˆØ²ÛŒØ¹ Ú¯ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ù†Ú¯ÙˆØ¦Ù†",
            color_discrete_sequence=px.colors.qualitative.Set2,
            hole=0.4
        )
        fig.update_traces(textposition='inside', textinfo='percent+label')
        st.plotly_chart(fig, use_container_width=True)

with tab2:
    st.header("ğŸ“ˆ Ù…ØµÙˆØ±Ø³Ø§Ø²ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
    
    viz_col1, viz_col2 = st.columns([1, 3])
    
    with viz_col1:
        st.subheader("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…ÙˆØ¯Ø§Ø±")
        
        plot_type = st.radio(
            "Ù†ÙˆØ¹ Ù†Ù…ÙˆØ¯Ø§Ø±:",
            ["Ù¾Ø±Ø§Ú©Ù†Ø¯Ú¯ÛŒ", "Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù…", "Ø¬Ø¹Ø¨Ù‡â€ŒØ§ÛŒ", "Ø¬ÙØªÛŒ"],
            horizontal=False
        )
        
        if plot_type == "Ù¾Ø±Ø§Ú©Ù†Ø¯Ú¯ÛŒ":
            x_axis = st.selectbox("Ù…Ø­ÙˆØ± X:", selected_features, index=0)
            y_axis = st.selectbox("Ù…Ø­ÙˆØ± Y:", selected_features, index=1 if len(selected_features) > 1 else 0)
            color_by = st.selectbox("Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ:", ["species", "island", "sex"], index=0)
            
        elif plot_type == "Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù…":
            feature = st.selectbox("ÙˆÛŒÚ˜Ú¯ÛŒ:", selected_features, index=0)
            bins = st.slider("ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§:", 10, 50, 30)
            
        elif plot_type == "Ø¬Ø¹Ø¨Ù‡â€ŒØ§ÛŒ":
            feature = st.selectbox("ÙˆÛŒÚ˜Ú¯ÛŒ:", selected_features, index=0)
            group_by = st.selectbox("Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ:", ["species", "island", "sex"], index=0)
    
    with viz_col2:
        if plot_type == "Ù¾Ø±Ø§Ú©Ù†Ø¯Ú¯ÛŒ":
            fig = px.scatter(
                df,
                x=x_axis,
                y=y_axis,
                color=color_by,
                size="body_mass_g" if "body_mass_g" in df.columns else None,
                hover_data=['species', 'island'],
                title=f"{x_axis} vs {y_axis}",
                opacity=0.7,
                color_discrete_sequence=px.colors.qualitative.Set1
            )
            st.plotly_chart(fig, use_container_width=True)
            
        elif plot_type == "Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù…":
            fig = px.histogram(
                df,
                x=feature,
                color="species",
                nbins=bins,
                marginal="box",
                title=f"ØªÙˆØ²ÛŒØ¹ {feature}",
                barmode="overlay",
                opacity=0.7
            )
            st.plotly_chart(fig, use_container_width=True)
            
        elif plot_type == "Ø¬Ø¹Ø¨Ù‡â€ŒØ§ÛŒ":
            fig = px.box(
                df,
                x=group_by,
                y=feature,
                color=group_by,
                title=f"ØªÙˆØ²ÛŒØ¹ {feature} Ø¨Ø± Ø§Ø³Ø§Ø³ {group_by}",
                points="all"
            )
            st.plotly_chart(fig, use_container_width=True)
            
        elif plot_type == "Ø¬ÙØªÛŒ":
            fig = px.scatter_matrix(
                df,
                dimensions=selected_features,
                color="species",
                title="Ù†Ù…ÙˆØ¯Ø§Ø± Ø¬ÙØªÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§",
                opacity=0.7
            )
            fig.update_traces(diagonal_visible=False)
            st.plotly_chart(fig, use_container_width=True)

# ============================================
# Û¹. Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
# ============================================

with tab3:
    st.header("ğŸ¤– Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„")
    
    if train_button and len(selected_features) >= 2:
        with st.status("ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„...", expanded=True) as status:
            
            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡
            st.write("ğŸ“Š Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
            X = df[selected_features]
            y = df["species_code"]
            
            # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42, stratify=y
            )
            
            st.write(f"ğŸ“ˆ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¢Ù…ÙˆØ²Ø´: {len(X_train)} Ù†Ù…ÙˆÙ†Ù‡")
            st.write(f"ğŸ“‰ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¬Ù…ÙˆØ¹Ù‡ ØªØ³Øª: {len(X_test)} Ù†Ù…ÙˆÙ†Ù‡")
            
            # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
            st.write(f"ğŸ¤– Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… {algorithm}...")
            start_time = time.time()
            
            model, metrics, y_pred, y_proba, best_params = train_and_evaluate(
                X_train, X_test, y_train, y_test, algorithm, use_grid_search
            )
            
            training_time = time.time() - start_time
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± session state
            st.session_state.model = model
            st.session_state.metrics = metrics
            st.session_state.training_time = training_time
            st.session_state.best_params = best_params
            
            status.update(label="âœ… Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!", state="complete")
        
        # ============================================
        # Û±Û°. Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
        # ============================================
        
        st.subheader("ğŸ“Š Ù†ØªØ§ÛŒØ¬ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„")
        
        # Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "ğŸ¯ Ø¯Ù‚Øª (Accuracy)",
                f"{metrics['accuracy']:.2%}",
                help="Ø¯Ø±ØµØ¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ ØµØ­ÛŒØ­"
            )
        with col2:
            st.metric(
                "ğŸ“Š Ø¯Ù‚Øª Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† (Precision)",
                f"{metrics['precision_macro']:.2%}",
                help="Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¯Ù‚Øª Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§"
            )
        with col3:
            st.metric(
                "ğŸ¯ ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ (Recall)",
                f"{metrics['recall_macro']:.2%}",
                help="Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø­Ø³Ø§Ø³ÛŒØª Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§"
            )
        with col4:
            st.metric(
                "ğŸ“ˆ F1-Score",
                f"{metrics['f1_macro']:.2%}",
                help="Ù‡Ø§Ø±Ù…ÙˆÙ†ÛŒÚ© Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¯Ù‚Øª Ùˆ ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ"
            )
        
        # Ø²Ù…Ø§Ù† Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§
        col1, col2 = st.columns(2)
        with col1:
            st.metric("â±ï¸ Ø²Ù…Ø§Ù† Ø¢Ù…ÙˆØ²Ø´", f"{training_time:.2f} Ø«Ø§Ù†ÛŒÙ‡")
        with col2:
            if best_params:
                st.metric("ğŸ”§ Ø¨Ù‡ØªØ±ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§", str(best_params))
        
        # Ú¯Ø²Ø§Ø±Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
        st.subheader("ğŸ“‹ Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ")
        
        target_names = ['Adelie', 'Chinstrap', 'Gentoo']
        report_dict = classification_report(
            y_test, y_pred, 
            target_names=target_names,
            output_dict=True
        )
        report_df = pd.DataFrame(report_dict).transpose()
        
        # Ø§Ø³ØªØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù† Ø¨Ù‡ Ú¯Ø²Ø§Ø±Ø´
        styled_df = report_df.style.format({
            'precision': '{:.2%}',
            'recall': '{:.2%}',
            'f1-score': '{:.2%}',
            'support': '{:.0f}'
        }).highlight_max(axis=0, color='lightgreen')
        
        st.dataframe(styled_df, use_container_width=True)
        
        # Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ
        st.subheader("ğŸ¯ Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ")
        
        cm = confusion_matrix(y_test, y_pred)
        
        fig = px.imshow(
            cm,
            x=target_names,
            y=target_names,
            text_auto=True,
            aspect="auto",
            color_continuous_scale="Blues",
            title="Confusion Matrix - Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ"
        )
        
        fig.update_layout(
            xaxis_title="Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø´Ø¯Ù‡",
            yaxis_title="ÙˆØ§Ù‚Ø¹ÛŒ",
            width=500,
            height=500
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù…ØªÙ‚Ø§Ø¨Ù„
        st.subheader("ğŸ”„ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù…ØªÙ‚Ø§Ø¨Ù„ (Cross-Validation)")
        
        with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù… Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù…ØªÙ‚Ø§Ø¨Ù„..."):
            from sklearn.model_selection import cross_val_score, StratifiedKFold
            
            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
            cv_scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¯Ù‚Øª CV", f"{cv_scores.mean():.2%}")
            with col2:
                st.metric("Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø±", f"{cv_scores.std():.2%}")
            with col3:
                st.metric("Ø¨Ø§Ø²Ù‡ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†", f"{cv_scores.mean() - 2*cv_scores.std():.2%} - {cv_scores.mean() + 2*cv_scores.std():.2%}")
            
            # Ù†Ù…ÙˆØ¯Ø§Ø± Ø§Ù…ØªÛŒØ§Ø²Ø§Øª CV
            fig = px.line(
                x=range(1, 6),
                y=cv_scores,
                markers=True,
                title="Ø§Ù…ØªÛŒØ§Ø²Ø§Øª Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù…ØªÙ‚Ø§Ø¨Ù„",
                labels={"x": "ÙÙˆÙ„Ø¯", "y": "Ø¯Ù‚Øª"}
            )
            fig.add_hline(y=cv_scores.mean(), line_dash="dash", line_color="red")
            st.plotly_chart(fig, use_container_width=True)
        
        # Ø°Ø®ÛŒØ±Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¢Ù…ÙˆØ²Ø´
        st.session_state.training_history.append({
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'algorithm': algorithm,
            'features': selected_features,
            'test_size': test_size,
            'accuracy': metrics['accuracy'],
            'f1_score': metrics['f1_macro'],
            'training_time': training_time
        })
        
    else:
        st.info("ğŸ‘ˆ Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´ØŒ Ø§Ø² Ù¾Ù†Ù„ Ø³Ù…Øª Ø±Ø§Ø³Øª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¯Ú©Ù…Ù‡ 'Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„' Ø±Ø§ Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯.")
        
        if st.session_state.model is not None:
            st.success("âœ… Ù…Ø¯Ù„ Ù‚Ø¨Ù„ÛŒä¾ç„¶ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª. Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø¢Ù† Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")
            
            # Ù†Ù…Ø§ÛŒØ´ Ø¢Ø®Ø±ÛŒÙ† Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡
            st.subheader("ğŸ“Š Ø¢Ø®Ø±ÛŒÙ† Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡")
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…", st.session_state.algorithm)
                st.metric("Ø¯Ù‚Øª", f"{st.session_state.metrics.get('accuracy', 0):.2%}")
            with col2:
                st.metric("Ø²Ù…Ø§Ù† Ø¢Ù…ÙˆØ²Ø´", f"{st.session_state.get('training_time', 0):.2f} Ø«Ø§Ù†ÛŒÙ‡")
                if 'best_params' in st.session_state and st.session_state.best_params:
                    st.metric("Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§", str(st.session_state.best_params))

# ============================================
# Û±Û±. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ
# ============================================

with tab4:
    st.header("ğŸ”® Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ Ú¯ÙˆÙ†Ù‡ Ù¾Ù†Ú¯ÙˆØ¦Ù†")
    
    if st.session_state.model is not None:
        
        st.markdown("""
        <div class="prediction-box">
            <h4>ğŸ“ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ù†Ú¯ÙˆØ¦Ù†</h4>
            <p>Ù…Ù‚Ø§Ø¯ÛŒØ± Ø±Ø§ Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ ØªØ§ Ø³ÛŒØ³ØªÙ… Ú¯ÙˆÙ†Ù‡ Ø±Ø§ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ù†Ø¯.</p>
        </div>
        """, unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ğŸ“ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†ÙˆÚ©**")
            bill_length = st.number_input(
                "Ø·ÙˆÙ„ Ù†ÙˆÚ© (Ù…ÛŒÙ„ÛŒâ€ŒÙ…ØªØ±):",
                min_value=30.0, max_value=60.0, value=45.0, step=0.1,
                format="%.1f",
                help="Ù…Ø­Ø¯ÙˆØ¯Ù‡: Û³Û° - Û¶Û° Ù…ÛŒÙ„ÛŒâ€ŒÙ…ØªØ±"
            )
            
            bill_depth = st.number_input(
                "Ø¹Ù…Ù‚ Ù†ÙˆÚ© (Ù…ÛŒÙ„ÛŒâ€ŒÙ…ØªØ±):",
                min_value=13.0, max_value=22.0, value=17.0, step=0.1,
                format="%.1f",
                help="Ù…Ø­Ø¯ÙˆØ¯Ù‡: Û±Û³ - Û²Û² Ù…ÛŒÙ„ÛŒâ€ŒÙ…ØªØ±"
            )
        
        with col2:
            st.markdown("**ğŸ¦© ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø¯Ù†**")
            flipper_length = st.number_input(
                "Ø·ÙˆÙ„ Ø¨Ø§Ù„Ú†Ù‡ (Ù…ÛŒÙ„ÛŒâ€ŒÙ…ØªØ±):",
                min_value=170.0, max_value=240.0, value=200.0, step=1.0,
                format="%.0f",
                help="Ù…Ø­Ø¯ÙˆØ¯Ù‡: Û±Û·Û° - Û²Û´Û° Ù…ÛŒÙ„ÛŒâ€ŒÙ…ØªØ±"
            )
            
            body_mass = st.number_input(
                "ÙˆØ²Ù† (Ú¯Ø±Ù…):",
                min_value=2500.0, max_value=6500.0, value=4200.0, step=50.0,
                format="%.0f",
                help="Ù…Ø­Ø¯ÙˆØ¯Ù‡: Û²ÛµÛ°Û° - Û¶ÛµÛ°Û° Ú¯Ø±Ù…"
            )
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¬Ù†Ø³ÛŒØª
        sex = st.selectbox(
            "Ø¬Ù†Ø³ÛŒØª:",
            options=["Male", "Female"],
            index=0,
            help="Ø§Ù†ØªØ®Ø§Ø¨ Ø¬Ù†Ø³ÛŒØª Ù¾Ù†Ú¯ÙˆØ¦Ù†"
        )
        sex_code = 0 if sex == "Male" else 1
        
        # Ø¯Ú©Ù…Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        predict_button = st.button(
            "ğŸ¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú¯ÙˆÙ†Ù‡",
            type="primary",
            use_container_width=True
        )
        
        if predict_button:
            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ ÙˆØ±ÙˆØ¯ÛŒ
            input_data = {}
            for i, feature in enumerate(st.session_state.selected_features):
                if feature == "bill_length_mm":
                    input_data[feature] = [bill_length]
                elif feature == "bill_depth_mm":
                    input_data[feature] = [bill_depth]
                elif feature == "flipper_length_mm":
                    input_data[feature] = [flipper_length]
                elif feature == "body_mass_g":
                    input_data[feature] = [body_mass]
            
            # Ø§Ú¯Ø± ÙˆÛŒÚ˜Ú¯ÛŒ Ø¬Ù†Ø³ÛŒØª Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø¨ÙˆØ¯
            if "sex_code" in st.session_state.selected_features:
                input_data["sex_code"] = [sex_code]
            
            input_df = pd.DataFrame(input_data)
            
            # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ØªØ±ØªÛŒØ¨ ØµØ­ÛŒØ­ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
            input_df = input_df[st.session_state.selected_features]
            
            try:
                # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
                prediction = st.session_state.model.predict(input_df)[0]
                
                # Ø§Ø­ØªÙ…Ø§Ù„ (Ø§Ú¯Ø± Ù…Ø¯Ù„ Ø§Ø² predict_proba Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ú©Ù†Ø¯)
                if hasattr(st.session_state.model, 'predict_proba'):
                    probabilities = st.session_state.model.predict_proba(input_df)[0]
                else:
                    probabilities = None
                
                # Ù†Ú¯Ø§Ø´Øª Ú©Ø¯ Ø¨Ù‡ Ù†Ø§Ù… Ú¯ÙˆÙ†Ù‡
                species_map = {0: 'Adelie', 1: 'Chinstrap', 2: 'Gentoo'}
                predicted_species = species_map[prediction]
                
                # Ù†Ù…Ø§ÛŒØ´ Ù†ØªÛŒØ¬Ù‡
                st.markdown("---")
                
                result_col1, result_col2 = st.columns([1, 1])
                
                with result_col1:
                    st.markdown(f"""
                    <div style='background-color: #4CAF50; padding: 30px; border-radius: 15px; text-align: center;'>
                        <h2 style='color: white; margin: 0;'>ğŸ§ {predicted_species}</h2>
                        <p style='color: white; font-size: 20px; margin-top: 10px;'>Ú¯ÙˆÙ†Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø´Ø¯Ù‡</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with result_col2:
                    if probabilities is not None:
                        st.subheader("ğŸ“Š Ø§Ø­ØªÙ…Ø§Ù„ ØªØ¹Ù„Ù‚ Ø¨Ù‡ Ù‡Ø± Ú¯ÙˆÙ†Ù‡")
                        
                        prob_df = pd.DataFrame({
                            'Ú¯ÙˆÙ†Ù‡': ['Adelie', 'Chinstrap', 'Gentoo'],
                            'Ø§Ø­ØªÙ…Ø§Ù„': probabilities
                        })
                        
                        fig = px.bar(
                            prob_df,
                            x='Ú¯ÙˆÙ†Ù‡',
                            y='Ø§Ø­ØªÙ…Ø§Ù„',
                            color='Ú¯ÙˆÙ†Ù‡',
                            text_auto='.2%',
                            title="Ø§Ø­ØªÙ…Ø§Ù„ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ",
                            color_discrete_map={
                                'Adelie': '#1f77b4',
                                'Chinstrap': '#ff7f0e',
                                'Gentoo': '#2ca02c'
                            }
                        )
                        fig.update_layout(showlegend=False)
                        st.plotly_chart(fig, use_container_width=True)
                
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
                st.session_state.predictions.append({
                    'timestamp': datetime.now().strftime("%H:%M:%S"),
                    'bill_length': bill_length,
                    'bill_depth': bill_depth,
                    'flipper_length': flipper_length,
                    'body_mass': body_mass,
                    'sex': sex,
                    'prediction': predicted_species,
                    'probabilities': probabilities.tolist() if probabilities is not None else None
                })
                
                st.balloons()
                
            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ: {str(e)}")
                st.info("ğŸ’¡ Ù„Ø·ÙØ§ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ Ù…Ø¯Ù„ Ø¨Ø§ Ù‡Ù…ÛŒÙ† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡ Ø§Ø³Øª.")
    
    else:
        st.warning("âš ï¸ Ø§Ø¨ØªØ¯Ø§ Ø¨Ø§ÛŒØ¯ ÛŒÚ© Ù…Ø¯Ù„ Ø±Ø§ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ù‡ÛŒØ¯!")
        st.info("ğŸ‘ˆ Ø¨Ù‡ ØªØ¨ 'Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ' Ø¨Ø±ÙˆÛŒØ¯ Ùˆ ÛŒÚ© Ù…Ø¯Ù„ Ø±Ø§ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ù‡ÛŒØ¯.")
    
    # Ù†Ù…Ø§ÛŒØ´ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
    if len(st.session_state.predictions) > 0:
        st.markdown("---")
        st.subheader("ğŸ“‹ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§")
        
        history_df = pd.DataFrame(st.session_state.predictions[-10:])  # Ø¢Ø®Ø±ÛŒÙ† Û±Û° Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        st.dataframe(history_df, use_container_width=True, hide_index=True)

# ============================================
# Û±Û². Ù†Ù…Ø§ÛŒØ´ Ú©Ø¯ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
# ============================================

if st.session_state.show_code:
    st.markdown("---")
    st.header("ğŸ“ Ú©Ø¯ Ù…Ù†Ø¨Ø¹ Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù†")
    
    with st.expander("Ù†Ù…Ø§ÛŒØ´ Ú©Ø¯ Ú©Ø§Ù…Ù„", expanded=False):
        with open(__file__, 'r', encoding='utf-8') as f:
            code = f.read()
        st.code(code, language='python')

# ============================================
# Û±Û³. ÙÙˆØªØ±
# ============================================

st.markdown("---")
st.markdown(f"""
<div style='text-align: center; color: gray; padding: 20px;'>
    <p>ğŸ§ Palmer Penguins Classifier | ØªÙˆØ³Ø¹Ù‡ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø¨Ø§ Streamlit Ùˆ â¤ï¸</p>
    <p>Ø´Ù†Ø§Ø³Ù‡ Ø³Ø´Ù†: {st.session_state.session_id} | ØªØ§Ø±ÛŒØ®: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</p>
    <p style='font-size: 0.8em;'>Â© 2026 Antarctic Research Program - All Rights Reserved</p>
</div>
""", unsafe_allow_html=True)